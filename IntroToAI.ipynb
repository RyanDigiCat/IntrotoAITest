{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code for this notebook.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, Javascript, display\n",
    "import IPython\n",
    "from ipywidgets import widgets\n",
    "import random\n",
    "\n",
    "# Create button that runs the below cell\n",
    "def run_below(ev):\n",
    "    display(Javascript('IPython.notebook.execute_cells([IPython.notebook.get_selected_index()+1])'))\n",
    "\n",
    "run_code_below_button = widgets.Button(description=\"Run code\")\n",
    "run_code_below_button.on_click(run_below)\n",
    "\n",
    "# Create toggle code button\n",
    "def toggle_code(for_next=False):\n",
    "    this_cell = \"\"\"$('div.cell.code_cell.rendered.selected')\"\"\"\n",
    "    next_cell = this_cell + '.next()'\n",
    "\n",
    "    toggle_text = 'Toggle show/hide code'  # text shown on toggle link\n",
    "    target_cell = this_cell  # target cell to control with toggle\n",
    "    js_hide_current = ''  # bit of JS to permanently hide code in current cell (only when toggling next cell)\n",
    "\n",
    "    if for_next:\n",
    "        target_cell = next_cell\n",
    "        # toggle_text += ' next cell'\n",
    "        js_hide_current = this_cell + '.find(\"div.input\").hide();'\n",
    "\n",
    "    js_f_name = 'code_toggle_{}'.format(str(random.randint(1,2**64)))\n",
    "\n",
    "    html = \"\"\"\n",
    "        <script>\n",
    "            function {f_name}() {{\n",
    "                {cell_selector}.find('div.input').toggle();\n",
    "            }}\n",
    "\n",
    "            {js_hide_current}\n",
    "        </script>\n",
    "\n",
    "        <a href=\"javascript:{f_name}()\">{toggle_text}</a>\n",
    "    \"\"\".format(\n",
    "        f_name=js_f_name,\n",
    "        cell_selector=target_cell,\n",
    "        js_hide_current=js_hide_current, \n",
    "        toggle_text=toggle_text\n",
    "    )\n",
    "\n",
    "    return HTML(html)\n",
    "\n",
    "# Create the run code and toggle code buttons for the cell below\n",
    "def create_buttons():\n",
    "    display(run_code_below_button)\n",
    "    display(toggle_code(for_next=True))\n",
    "    \n",
    "# Create a button that hides all the code in the notebook and autoruns on the notebook\n",
    "hide_all_code_button = HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code for this notebook.\"></form>''')\n",
    "display(hide_all_code_button)\n",
    "\n",
    "\n",
    "# CODE BELOW WAS SUPPOSED TO BE A SMARTER TOGGLE BUTTON - DOESNT WORK YET\n",
    "# javascript_functions = {False: \"hide()\", True: \"show()\"}\n",
    "# button_descriptions  = {False: \"Show code\", True: \"Hide code\"}\n",
    "# STATE = False\n",
    "# def toggle_code(ev):\n",
    "#     import random\n",
    "#     for_next = True\n",
    "#     this_cell = \"\"\"$('div.cell.code_cell.rendered.selected')\"\"\"\n",
    "#     next_cell = this_cell + '.next()'\n",
    "\n",
    "#     toggle_text = 'Toggle show/hide'  # text shown on toggle link\n",
    "#     target_cell = this_cell  # target cell to control with toggle\n",
    "#     js_hide_current = ''  # bit of JS to permanently hide code in current cell (only when toggling next cell)\n",
    "\n",
    "#     if for_next:\n",
    "#         target_cell = next_cell\n",
    "#         toggle_text += ' next cell'\n",
    "#         js_hide_current = this_cell + '.find(\"div.input\").hide();'\n",
    "\n",
    "#     js_f_name = 'code_toggle_{}'.format(str(random.randint(1,2**64)))\n",
    "\n",
    "#     output = \"\"\"\n",
    "#         <script>\n",
    "#             function {f_name}() {{\n",
    "#                 {cell_selector}.find('div.input').toggle();\n",
    "#             }}\n",
    "\n",
    "#             {js_hide_current}\n",
    "#         </script>\n",
    "\n",
    "#         <a href=\"javascript:{f_name}()\"></a>\n",
    "#     \"\"\".format(\n",
    "#         f_name=js_f_name,\n",
    "#         cell_selector=target_cell,\n",
    "#         js_hide_current=js_hide_current, \n",
    "#     )\n",
    "\n",
    "#     display(HTML(output))\n",
    "\n",
    "\n",
    "# def button_action(value):\n",
    "\n",
    "#     \"\"\"\n",
    "#     Calls the toggle_code function and updates the button description.\n",
    "#     \"\"\"\n",
    "\n",
    "#     state = value.new\n",
    "\n",
    "#     toggle_code()\n",
    "#     # Change the state\n",
    "#     state = not state\n",
    "\n",
    "#     value.owner.description = button_descriptions[state]\n",
    "    \n",
    "# def create_buttons():\n",
    "#     state = False\n",
    "#     #toggle_code(state)\n",
    "#     code_toggle_button = widgets.ToggleButton(description = button_descriptions[state])\n",
    "#     code_toggle_button.observe(button_action, \"value\")\n",
    "#     display(widgets.HBox([run_code_below_button, code_toggle_button]))\n",
    "\n",
    "\n",
    "\n",
    "# ALSO DOESNT WORK YET\n",
    "# # Create toggle code button\n",
    "# def toggle_code(for_next=True):\n",
    "#     this_cell = \"\"\"$('div.cell.code_cell.rendered.selected')\"\"\"\n",
    "#     next_cell = this_cell + '.next()'\n",
    "\n",
    "#     toggle_text = 'Toggle show/hide code'  # text shown on toggle link\n",
    "#     target_cell = this_cell  # target cell to control with toggle\n",
    "#     js_hide_current = ''  # bit of JS to permanently hide code in current cell (only when toggling next cell)\n",
    "\n",
    "#     if for_next:\n",
    "#         target_cell = next_cell\n",
    "#         # toggle_text += ' next cell'\n",
    "#         js_hide_current = this_cell + '.find(\"div.input\").hide();'\n",
    "\n",
    "#     js_f_name = 'code_toggle_{}'.format(str(random.randint(1,2**64)))\n",
    "\n",
    "#     html = \"\"\"\n",
    "#         <script>\n",
    "#             function {f_name}() {{\n",
    "#                 {cell_selector}.find('div.input').toggle();\n",
    "#             }}\n",
    "\n",
    "#             {js_hide_current}\n",
    "#         </script>\n",
    "\n",
    "#         <a href=\"javascript:{f_name}()\">{toggle_text}</a>\n",
    "#     \"\"\".format(\n",
    "#         f_name=js_f_name,\n",
    "#         cell_selector=target_cell,\n",
    "#         js_hide_current=js_hide_current, \n",
    "#         toggle_text=toggle_text\n",
    "#     )\n",
    "\n",
    "#     return HTML(html)\n",
    "\n",
    "# toggle_code_below_button = widgets.Button(description=\"Show/hide code\")\n",
    "# toggle_code_below_button.on_click(toggle_code)\n",
    "\n",
    "# def create_buttons():\n",
    "#     display(widgets.HBox([run_code_below_button, toggle_code_below_button]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Basic dependencies\n",
    "import math\n",
    "\n",
    "# Numerical and dataframe dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import altair as alt\n",
    "#alt.renderers.enable('notebook')\n",
    "from livelossplot import PlotLosses\n",
    "from livelossplot.tf_keras import PlotLossesCallback\n",
    "\n",
    "# Machine Learning libraries\n",
    "import sklearn.metrics as metrics\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "tf.get_logger().setLevel('INFO') # Ignore warning/depreciation messages in the logger\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Set overall global variables\n",
    "HEIGHT = 32\n",
    "WIDTH = 32\n",
    "NUM_CHANNELS = 3\n",
    "IMG_SHAPE = (HEIGHT, WIDTH, NUM_CHANNELS)\n",
    "CLASS_NAMES = {\n",
    "    0: 'airplane',\n",
    "    1: 'automobile',\n",
    "    2: 'bird',\n",
    "    3: 'cat',\n",
    "    4: 'deer',\n",
    "    5: 'dog',\n",
    "    6: 'frog',\n",
    "    7: 'horse',\n",
    "    8: 'ship',\n",
    "    9: 'truck'\n",
    "}\n",
    "NUM_CLASSES = len(CLASS_NAMES) # 10\n",
    "\n",
    "BATCH_SIZE = 32 #Default batch size, could be changed\n",
    "\n",
    "DATA_LOADED = False # Add in more of these?!?!\n",
    "DATA_PREPROCESSED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def print_confusion_matrix(predicted_labels, true_labels, class_names, figsize = (20,10), fontsize=14):\n",
    "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    confusion_matrix: numpy.ndarray\n",
    "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
    "        Similarly constructed ndarrays can also be used.\n",
    "    class_names: list\n",
    "        An ordered list of class names, in the order they index the given confusion matrix.\n",
    "    figsize: tuple\n",
    "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
    "        the second determining the vertical size. Defaults to (10,7).\n",
    "    fontsize: int\n",
    "        Font size for axes labels. Defaults to 14.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The resulting confusion matrix figure\n",
    "    \"\"\"\n",
    "    confusion_matrix = metrics.confusion_matrix(true_labels, predicted_labels)\n",
    "    confusion_matrix_norm = confusion_matrix.astype('float') / confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    cm_sum = np.sum(df_cm, axis=1)\n",
    "    cm_perc = df_cm / cm_sum.astype(float) * 100\n",
    "    \n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    annot = np.empty_like(df_cm).astype(str)\n",
    "    nrows, ncols = df_cm.shape\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            c = df_cm.iloc[i][j]\n",
    "            p = cm_perc.iloc[i][j]\n",
    "            if i == j:\n",
    "                s = cm_sum[i]\n",
    "                annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "            elif c == 0:\n",
    "                annot[i, j] = ''\n",
    "            else:\n",
    "                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "    \n",
    "    heatmap = sns.heatmap(df_cm, annot=annot, fmt='')\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    \n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# ü§ñ Intro to AI Notebook ü§ñ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/IntroToAIOpeningImage.jpeg\" width=\"600\">\n",
    "\n",
    "Welcome to the Jupyter notebook! This is the classic environment for a Data Scientist and Machine Learning Engineer. This is often where we experiment with pieces of code, look and analyse data and build machine learning models. It is also a useful tool for presenting the findings of our analyses in a clear manner.\n",
    "\n",
    "We have set this notebook up in a special and unusual way today - all the code cells will be hidden, so you don't have to worry about it. But, if you would like to take a look then you can toggle the code on and off at any time!\n",
    "\n",
    "You can also toggle on and off the code in the entire notebook with the button at the top.\n",
    "\n",
    "The way we will interact with this notebook is as below:\n",
    "- The \"run code\" cell will run the code in the hidden cell\n",
    "- The toggle code button will allow you to see the underlying code, if you wish\n",
    "\n",
    "You can try out these buttons below! The buttons below will print out the phrase ```Hello world``` - any good programmers first piece of code!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33eb46edbe66448bae158b3a4a1a45ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Run code', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_3770104800702426309() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_3770104800702426309()\">Toggle show/hide code</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_buttons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Hello world!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¬ß0: Introduction\n",
    "The intention of this notebook is to give you an interactive and friendly introduction to AI and Machine Learning by stepping through a classic data science/Machine Learning workflow.\n",
    "\n",
    "<img src=\"images/DataScienceLifeCycle.jpg\" width=\"800\" title=\"Data Science Workflow\">\n",
    "\n",
    "A classic Machine Learning workflow is made up of the following general steps:\n",
    "\n",
    "* Discovery phase\n",
    "    * Identifying business challenges, bottlenecks and improvement/optimisation opportunities\n",
    "    * Define Problem \n",
    "        * Specify Inputs & Outputs\n",
    "    * Data Mapping\n",
    "        * Understanding if the data required is already collected/attainable\n",
    "        * Looking at leveraging similar online/open source datasets or purchasing datasets\n",
    "        * **Are you collecting the right kinds of data?** - e.g if you wish to predict the outcome of a certain process you are monitoring, do you collect the outcome data you want to predict? If not, then an ML algorithm will not be able to learn. Can do rule based approaches, but not ML.\n",
    "        * Data Quality\n",
    "* Data Preparation Phase\n",
    "    * Data Collection\n",
    "    * Exploratory data analysis (EDA)\n",
    "        * Loading the data\n",
    "        * Data Quality\n",
    "        * Data Understanding\n",
    "        * Visualization \n",
    "    * Data Preprocessing / Cleaning\n",
    "* Model Planning Phase\n",
    "    * Model Design\n",
    "    * Training\n",
    "* Model Building Phase\n",
    "    * Initial Offline Evaluation\n",
    "* Communicate Results\n",
    "\n",
    "* Operationalise\n",
    "    * Model Deployment\n",
    "    * Online Evaluation\n",
    "    * Monitoring\n",
    "    * Model Maintenance\n",
    "    * Diagnosis\n",
    "    * Retraining\n",
    "\n",
    "<img src=\"images/MLWorkflow.png\" width=\"800\" title=\"ML Workflow\">\n",
    "\n",
    "<img src=\"images/MLWorkflowLowLevel.png\" title=\"Low Level ML Workflow\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¬ß1: Discovery Phase\n",
    "While this is an important element of any good Machine Learning project (see the \"Data Science Process\" talk), we defer the details for this workshop. In particular, suppose the outcomes of this were as follows:\n",
    "\n",
    "### ¬ß1.1 Problem Definition\n",
    "The problem definition that business X cares about is the classification of images. In particular, they want to develop a system that will take in RGB coloured images, and classify them into one of 10 pre-defined classes. These classes are:\n",
    "\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "#### ¬ß1.1.1 Inputs\n",
    "The input will be a 32x32 pixel RGB colour photograph of objects from these 10 classes\n",
    "\n",
    "#### ¬ß1.1.2 Outputs\n",
    "The output of the Machine Learning model will be a prediction of the class\n",
    "\n",
    "### ¬ß1.2 Data Mapping\n",
    "For the purposes of this exercise, we will defer data mapping. We can assume that the data has already been collected. However, it is worth stressing that this is a really important part of the process. The other talks such as **Data for AI** and **Data Science Process** go into this more, but it is importnat to think about whether or not the problem you have is suitable for machine learning before embarking on it to derisk it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¬ß2: Data Preparation Phase\n",
    "In this phase, we will prepare our inputs (defined above) ready for the models to be built. We will also perform some \"Exploratory Data Analysis\" (EDA) to look at our data and the type of data that we have.\n",
    "\n",
    "### ¬ß2.1: Data Collection\n",
    "Usually, we have to track down our data which might be sitting in many different internal systems. Typically, we would like to recieve a csv format (if the data is small enough) with corresponding \"features\" of the input and the \"output variable\" we are trying to track (if we have tabular data, which is the case for most predictions and time series models). You can think of this as a \"barebones\" excel spreadsheet - we would want the headers for the variable names across the top and the values in a table. We would also want to understand what each of the variables represent - so a brief description in a supporting document - as well as which are believed to be important for predicting the target variable. Additionally, it is also relevant to identify which variables to remove! For example, it would be unethical to predict someones loan amount based on their gender or age. See more in the \"Ethics for AI\" talk.\n",
    "\n",
    "For our problem, we are working with Image data, so our dataset is a collection of images. For data collection here, we will actually just be using an open source (public) dataset that anyone can access, so we dont have any data collection issues. We will be working with the CIFAR dataset.\n",
    "\n",
    "CIFAR is an acronym that stands for the [Canadian Institute For Advanced Research](https://www.cs.toronto.edu/~kriz/cifar.html) and the CIFAR-10 dataset was developed along with the CIFAR-100 dataset by researchers at the CIFAR institute.\n",
    "\n",
    "The dataset is comprised of 60,000 32√ó32 pixel color photographs of objects from 10 classes, such as frogs, birds, cats, ships, etc. The class labels and their standard associated integer values are listed below.\n",
    "\n",
    "* 0: airplane\n",
    "* 1: automobile\n",
    "* 2: bird\n",
    "* 3: cat\n",
    "* 4: deer\n",
    "* 5: dog\n",
    "* 6: frog\n",
    "* 7: horse\n",
    "* 8: ship\n",
    "* 9: truck\n",
    "\n",
    "These are very small images, much smaller than a typical photograph, and the dataset was intended for computer vision research.\n",
    "\n",
    "CIFAR-10 is a well-understood dataset and widely used for benchmarking computer vision algorithms in the field of machine learning. The problem is *‚Äúsolved‚Äù*. It is relatively straightforward to achieve 80% classification accuracy. Top performance on the problem is achieved by deep learning convolutional neural networks with a classification accuracy of around 97% on the test dataset. Human accuracy is around 94%. \n",
    "\n",
    "Today, we will show you how you can build an image recognition classifier to be able to achieve human accuracy.\n",
    "\n",
    "Click on the button below to download the dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33eb46edbe66448bae158b3a4a1a45ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Run code', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_7849628010503401139() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_7849628010503401139()\">Toggle show/hide code</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_buttons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Really we should also create a validation set - check if we want to do this or will it be too confusing?\n",
    "# NUM_VAL_IMAGES = 10000\n",
    "# from sklearn.model_selection import train_test_split \n",
    "# We will use this function to split our \"training\" set into our \"training\" + \"validation\" set - confusing name!\n",
    "# (X_train, X_val), (y_train, y_val) = train_test_split(X_train, y_train, stratify=y_train, test_size=NUM_VAL_IMAGES)\n",
    "# For now lets just set X_val, y_val to X_test, y_test\n",
    "X_val, y_val = X_test, y_test\n",
    "\n",
    "# Set global variables\n",
    "N_TRAIN = len(X_train)\n",
    "N_VAL = len(X_val)\n",
    "N_TEST = len(X_test)\n",
    "\n",
    "print('Dataset loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¬ß2.2: Exploratory Data Analysis (EDA)\n",
    "In this section, we use graphical and numerical techniques to begin uncovering the structure of our data.\n",
    "\n",
    "- Which variables suggest interesting relationships?\n",
    "- Which observations are unusual?\n",
    "\n",
    "- X.1 Data Collection\n",
    "- X.2 Visualization\n",
    "- X.3 Data Preprocessing\n",
    "- X.4 Data Cleaning\n",
    "\n",
    "\n",
    "### ¬ß2.2.1: Data Preprocessing\n",
    "One key thing for computers is that we have to transform everything over to numbers - so when we are dealing with image data (or text data) we have to find a way of mapping each of the images into numbers that a computer can understand. Luckily, with RGB images we can do that. RGB Images are made up of pixels, and each pixel is a tuple $(R,G,B) = (x,y,z)$ where $x,y,z$ are all numbers between 0 and 255. That means we can instead represent each image as a *tensor of numbers*. We are going to define operations on them and build machine learning models so that the data can *flow* through these sets of processes (hence the name *Tensorflow* by Google, if you've heard of it!). The image below represents this process:\n",
    "\n",
    "<img src=\"images/RGBImage.png\" width=\"600\" title=\"RGB Image converted into a tensor\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33eb46edbe66448bae158b3a4a1a45ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Run code', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_9183599570316436269() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_9183599570316436269()\">Toggle show/hide code</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_buttons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the counts of each of the image types and put them in a dataframe\n",
    "set_value_counts = pd.DataFrame([\n",
    "    np.unique(y_train, return_counts=True)[1],\n",
    "    np.unique(y_val, return_counts=True)[1],\n",
    "    np.unique(y_test, return_counts=True)[1]\n",
    "], index=['Training Set', 'Validation Set', 'Testing Set'])\n",
    "\n",
    "set_value_counts.columns = set_value_counts.columns.map(CLASS_NAMES)\n",
    "set_value_counts.columns.name = 'Image Class'\n",
    "set_value_counts.index.name = 'Set Name'\n",
    "\n",
    "# Transform the dataframe into a format suitable for altair\n",
    "source = set_value_counts.reset_index().melt('Set Name')\n",
    "\n",
    "# Create a multi selection index with every class pre-initialised\n",
    "selection = alt.selection_multi(\n",
    "    fields=[\"Image Class\"]\n",
    ")\n",
    "color = alt.condition(\n",
    "    selection, alt.Color(\"Image Class:N\", legend=None), alt.value(\"lightgray\")\n",
    ")\n",
    "\n",
    "barchart = (\n",
    "    alt.Chart(source)\n",
    "    .mark_bar()\n",
    "    .encode(x=alt.X(\"Set Name:N\", axis=alt.Axis(labelAngle=-45)),\n",
    "            y=\"value:Q\", color=color, \n",
    "            tooltip=[alt.Tooltip(\"Image Class:N\", title='Image Class'), \n",
    "                     alt.Tooltip(\"value:N\", title='Number of Images')])\n",
    "    .add_selection(selection)\n",
    "    .properties(width=700,height=450)\n",
    ")\n",
    "\n",
    "legend = (\n",
    "    alt.Chart(source)\n",
    "    .mark_point()\n",
    "    .encode(y=alt.Y(\"Image Class:N\", axis=alt.Axis(orient=\"right\")), color=color)\n",
    "    .add_selection(selection)\n",
    ")\n",
    "\n",
    "barchart | legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33eb46edbe66448bae158b3a4a1a45ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Run code', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_4435999817162140458() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_4435999817162140458()\">Toggle show/hide code</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_buttons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, widgets\n",
    "SAMPLE_SIZE = 101\n",
    "img_idx_slider = widgets.IntSlider(value=0, min=0, max=SAMPLE_SIZE - 1, description=\"Image index\", \n",
    "                                   layout=widgets.Layout(width='100%', height='50px'))\n",
    "\n",
    "train_images_sample = {class_name: X_train[(y_train == class_idx).squeeze()][:SAMPLE_SIZE] \n",
    "                       for class_idx, class_name in CLASS_NAMES.items()}\n",
    "\n",
    "@interact(i=img_idx_slider)\n",
    "def visualize_prediction(i=0):\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(20, 10))\n",
    "    for ax, class_name in zip(axes.flat, CLASS_NAMES.values()):\n",
    "        ax.imshow(train_images_sample[class_name][i].squeeze())\n",
    "        ax.set_title(f\"Class / label: {class_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X.3 Data Preprocessing\n",
    "Data preprocessing refers to the transformations and input pipelines we create and apply to our data before we feed it to the (machine learning) algorithm.\n",
    "\n",
    "Often, data collected in a raw format is not feasible for the analysis - it is \"messy\". We gop through a process of \"cleaning the data\" to ensure that our algortithms can learn well. Thgis varies massively depending on the application we are building, but typical things we do in this stage are:\n",
    "\n",
    "- Introducing missing values and treating them (replacing by average values)\n",
    "- Noise filtering (e.g rolling averages to reduce the noise in time series application)\n",
    "- Data discretization (\"bucketing\" the values into groups)\n",
    "- Normalization and standardization\n",
    "- Feature selection (either manually via experimentation or using other machine learning techniques to reduce the dataset to its key characteristics)\n",
    "\n",
    "For Image data, standard techniques are:\n",
    "- One\n",
    "- Two etc...\n",
    "\n",
    "For tabular data, standard techniques are:\n",
    "- Missing value imputation (replacing missing values with sensible values)\n",
    "    - If we have a table of features, and certain missing values (e.g a feature wasnt recorded for a particular person), we could replace that feature with the average feature overall or similar\n",
    "    - For time series data, if a particular sensor failed to get a reading at a particular time, we could replace it with the average of the previous and subseqwuent recording (\"linear interpolation\")\n",
    "    - etc...\n",
    "\n",
    "We apply minimal processing to our data for this workshop. \n",
    "\n",
    "It turns out all neural networks perform better when their input values are smaller (e.g between 0 and 1), rather than large input values. One way we can do this for images is to divide each of the RGB numbers by 255. Meaning we go from a number between 0 and 255 to a number between 0 and 1. It reflects the same information but it just helps the neural networks learn better.\n",
    "\n",
    "Click the button below to preprocess the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33eb46edbe66448bae158b3a4a1a45ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Run code', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_15799976914453536869() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_15799976914453536869()\">Toggle show/hide code</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_buttons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DATA_PREPROCESSED:\n",
    "    # Preprocessing - normalise the images\n",
    "    X_train, X_val, X_test = X_train / 255.0, X_val / 255.0, X_test / 255.0\n",
    "    \n",
    "    DATA_PREPROCESSED = True\n",
    "\n",
    "print('Images preprocessed successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To add to** Define NN and CNN baselines and train NN baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33eb46edbe66448bae158b3a4a1a45ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Run code', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_13785130308608898838() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_13785130308608898838()\">Toggle show/hide code</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_buttons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DATA_PREPROCESSED:\n",
    "    raise \"Please preprocess the data before you train the neural networks - click the above button!\"\n",
    "\n",
    "# Create the baseline model described in the text above (TODO)\n",
    "baseline_NN_model = tf.keras.Sequential([\n",
    "    # Flatten RGB image + NN\n",
    "    tf.keras.layers.Flatten(input_shape=IMG_SHAPE, name='Flatten'),\n",
    "    tf.keras.layers.Dense(128, activation='relu', name='Dense_1'),\n",
    "    tf.keras.layers.Dense(64, activation='relu', name='Dense_2'),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax', name='Predictions')\n",
    "], name='Baseline_NN_Model')\n",
    "\n",
    "baseline_CNN_model=tf.keras.models.Sequential([\n",
    "    # Conv + Max Pool - Block 1\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=IMG_SHAPE),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # Conv + Max Pool - Block 2\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten + Basic NN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "], name='Baseline_CNN_Model')\n",
    "\n",
    "# Print model summary - potentially remove - or print out image here\n",
    "print(baseline_NN_model.summary())\n",
    "\n",
    "# Compile the model - we will use the Adam optimiser and categorical crossentropy loss, logging the accuracy\n",
    "# TODO: Tensorboard here and integrate callbacks into live tracking below? Potentially just a cleaner interface\n",
    "baseline_NN_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")  \n",
    "\n",
    "# Fit the baseline model to the training data, validating against the validation data\n",
    "baseline_NN_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[PlotLossesCallback()],\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To add to** Train CNN model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33eb46edbe66448bae158b3a4a1a45ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Run code', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_12428968596287313350() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_12428968596287313350()\">Toggle show/hide code</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_buttons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_CNN_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")  \n",
    "\n",
    "# Fit the baseline model to the training data, validating against the validation data\n",
    "baseline_CNN_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[PlotLossesCallback()],\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_mobilenet(x, y, for_mobilenet=False):\n",
    "#     x = tf.image.resize(x, (224, 224), method='bicubic') # could make `rows` in [96, 128, 160, 192, 224]?\n",
    "#     x = tf.image.per_image_standardization(x)\n",
    "#     return x, y\n",
    "\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "# test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "# tf.random.set_seed(42)\n",
    "# train_dataset = train_dataset.map(augmentation).map(preprocess_mobilenet).shuffle(NUM_TRAIN_SAMPLES).batch(BS_PER_GPU * NUM_GPUS, drop_remainder=True)\n",
    "# test_dataset = test_dataset.map(preprocess_mobilenet).batch(BS_PER_GPU * NUM_GPUS, drop_remainder=True)\n",
    "\n",
    "\n",
    "# # Create the base model from the pre-trained model MobileNet V2\n",
    "# base_model = tf.keras.applications.MobileNetV2(input_shape=(224,224,3),\n",
    "#                                                include_top=False,\n",
    "#                                                weights='imagenet')\n",
    "\n",
    "# for image_batch, label_batch in train_dataset.take(1):\n",
    "#    pass\n",
    "\n",
    "# print('Image batch shape:', image_batch.shape)\n",
    "\n",
    "# feature_batch = base_model(image_batch)\n",
    "# print(feature_batch.shape)\n",
    "\n",
    "# base_model.trainable = False\n",
    "\n",
    "# global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "# feature_batch_average = global_average_layer(feature_batch)\n",
    "# print(feature_batch_average.shape)\n",
    "\n",
    "# prediction_layer = keras.layers.Dense(NUM_CLASSES)\n",
    "# prediction_batch = prediction_layer(feature_batch_average)\n",
    "# print(prediction_batch.shape)\n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "#   base_model,\n",
    "#   global_average_layer,\n",
    "#   prediction_layer\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a basic \"baseline\" model - just flattening the features and mapping to a dense layer.\n",
    "# Visualise training accuracy and losses. Predictions of the two models\n",
    "# Confusion matrix of two models **\n",
    "# Visualise predictions of two models.\n",
    "# tSNE embeddings of test images and 10 kNN with autonaming of clusters by class, perhaps dots are test images. Interactive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Investigation\n",
    "\n",
    "**To add to** Plot heatmap of confusion matrix of baseline NN model preds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33eb46edbe66448bae158b3a4a1a45ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Run code', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_14924429994595585602() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_14924429994595585602()\">Toggle show/hide code</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_buttons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_outputs(model, inputs):\n",
    "    model_probs = model.predict(inputs)\n",
    "    model_preds = model_probs.argmax(axis=1)\n",
    "    return model_probs, model_preds\n",
    "\n",
    "baseline_NN_model_probs, baseline_NN_model_preds = get_model_outputs(baseline_NN_model, X_test)\n",
    "print_confusion_matrix(baseline_NN_model_preds, y_test, class_names=CLASS_NAMES.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To add to** Visualise predictions of the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33eb46edbe66448bae158b3a4a1a45ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Run code', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_16620701483763741334() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_16620701483763741334()\">Toggle show/hide code</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_buttons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Nice image slider: https://sanjayasubedi.com.np/deeplearning/tensorflow-2-first-neural-network-for-fashion-mnist/\n",
    "from ipywidgets import interact, widgets\n",
    "img_idx_slider = widgets.IntSlider(value=0, min=0, max=len(X_test)-1, description=\"Image index\",\n",
    "                                   layout=widgets.Layout(width='100%', height='50px'))\n",
    "\n",
    "@interact(i=img_idx_slider)\n",
    "def visualize_prediction(i=0):\n",
    "    img_probs, img_pred = baseline_NN_model_probs[i], baseline_NN_model_preds[i].squeeze()\n",
    "    fix, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax1.imshow(X_test[i])\n",
    "    ax1.set_title(f\"Label: {CLASS_NAMES[y_test[i][0]]}\")\n",
    "    ax1.set_xlabel(f\"Prediction: {CLASS_NAMES[img_pred]}\")\n",
    "\n",
    "    sns.barplot(x=list(CLASS_NAMES.values()), y=img_probs*100, ax=ax2, \n",
    "                palette=['grey' if (prob < max(img_probs)) else 'gold' for prob in img_probs])\n",
    "    plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To add into above** \"Live training\" a SOTA model but loading pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33eb46edbe66448bae158b3a4a1a45ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Run code', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_4200420377020165969() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_4200420377020165969()\">Toggle show/hide code</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_buttons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "liveplot = PlotLosses(skip_first=0)\n",
    "with open('VGG_results.txt', 'r') as vgg_results:\n",
    "    for line_count, line in enumerate(vgg_results):\n",
    "        # If we have an even line then it will say Epoch x/50 - extract the epoch number\n",
    "        if line_count % 2 == 0:\n",
    "            epoch_num = line_count // 2 + 1\n",
    "        else:\n",
    "            loss, acc, val_loss, val_acc = (float(line.split(\": \")[metric_num][:6]) for metric_num in range(1,5))\n",
    "            liveplot.update({\n",
    "                'loss': loss,\n",
    "                'val_loss': val_loss,\n",
    "                'accuracy': acc,\n",
    "                'val_accuracy': val_acc\n",
    "            })\n",
    "            liveplot.draw()\n",
    "            time.sleep(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRYING TO GET VGG16 TO WORK - COULD JUST IMPORT FROM VGG16.PY...\n",
    "vgg_model = tf.keras.Sequential([ \n",
    "    tf.keras.layers.Lambda(lambda x: tf.transpose(x, [0,3,1,2]), input_shape = IMG_SHAPE),\n",
    "    # Block 1\n",
    "    tf.keras.layers.Convolution2D(64, 3, 3, activation='relu', padding='same', name='block1_conv1', \n",
    "                                  input_shape=IMG_SHAPE),\n",
    "    tf.keras.layers.Convolution2D(64, 3, 3, activation='relu', padding='same', name='block1_conv2'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool'),\n",
    "\n",
    "    # Block 2\n",
    "    tf.keras.layers.Convolution2D(128, 3, 3, activation='relu', padding='same', name='block2_conv1'),\n",
    "    tf.keras.layers.Convolution2D(128, 3, 3, activation='relu', padding='same', name='block2_conv2'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool'),\n",
    "\n",
    "    # Block 3\n",
    "    tf.keras.layers.Convolution2D(256, 3, 3, activation='relu', padding='same', name='block3_conv1'),\n",
    "    tf.keras.layers.Convolution2D(256, 3, 3, activation='relu', padding='same', name='block3_conv2'),\n",
    "    tf.keras.layers.Convolution2D(256, 3, 3, activation='relu', padding='same', name='block3_conv3'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool'),\n",
    "    \n",
    "    # Block 4\n",
    "    tf.keras.layers.Convolution2D(512, 3, 3, activation='relu', padding='same', name='block4_conv1'),\n",
    "    tf.keras.layers.Convolution2D(512, 3, 3, activation='relu', padding='same', name='block4_conv2'),\n",
    "    tf.keras.layers.Convolution2D(512, 3, 3, activation='relu', padding='same', name='block4_conv3'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool'),\n",
    "\n",
    "    # Block 5\n",
    "    tf.keras.layers.Convolution2D(512, 3, 3, activation='relu', padding='same', name='block5_conv1'),\n",
    "    tf.keras.layers.Convolution2D(512, 3, 3, activation='relu', padding='same', name='block5_conv2'),\n",
    "    tf.keras.layers.Convolution2D(512, 3, 3, activation='relu', padding='same', name='block5_conv3'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool'),\n",
    "\n",
    "    # Classification block\n",
    "    tf.keras.layers.Flatten(name='flatten'),\n",
    "    tf.keras.layers.Dense(4096, activation='relu', name='fc1'),\n",
    "    tf.keras.layers.Dense(4096, activation='relu', name='fc2'),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax', name='predictions')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOs: visualise last layer embeddings of VGG-16 and tsne clusterings coloured by label\n",
    "# Possible TODO: Visualise \"what the network sees when making its decision\" ?? - Potential extension\n",
    "# https://github.com/marcotcr/lime/blob/master/doc/notebooks/Tutorial%20-%20Image%20Classification%20Keras.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work\n",
    "### The CIFAR-100 dataset\n",
    "This dataset is just like the CIFAR-10, except it has 100 classes containing 600 images each. There are 500 training images and 100 testing images per class. The 100 classes in the CIFAR-100 are grouped into 20 superclasses. Each image comes with a \"fine\" label (the class to which it belongs) and a \"coarse\" label (the superclass to which it belongs).\n",
    "Here is the list of classes in the CIFAR-100:\n",
    "\n",
    "\n",
    "| Superclass | Classes |\n",
    "|:----------|:--------:|\n",
    "| aquatic mammals | beaver, dolphin, otter, seal, whale |\n",
    "| fish | aquarium fish, flatfish, ray, shark, trout |\n",
    "| flowers | orchids, poppies, roses, sunflowers, tulips |\n",
    "| food containers | bottles, bowls, cans, cups, plates |\n",
    "| fruit and vegetables | apples, mushrooms, oranges, pears, sweet peppers |\n",
    "| household electrical devices | clock, computer keyboard, lamp, telephone, television |\n",
    "| household furniture | bed, chair, couch, table, wardrobe |\n",
    "| insects | bee, beetle, butterfly, caterpillar, cockroach |\n",
    "| large carnivores | bear, leopard, lion, tiger, wolf |\n",
    "| large man-made outdoor things | bridge, castle, house, road, skyscraper |\n",
    "| large natural outdoor scenes | cloud, forest, mountain, plain, sea |\n",
    "| large omnivores and herbivores | camel, cattle, chimpanzee, elephant, kangaroo |\n",
    "| medium-sized mammals | fox, porcupine, possum, raccoon, skunk |\n",
    "| non-insect invertebrates | crab, lobster, snail, spider, worm |\n",
    "| people | baby, boy, girl, man, woman |\n",
    "| reptiles | crocodile, dinosaur, lizard, snake, turtle |\n",
    "| small mammals | hamster, mouse, rabbit, shrew, squirrel |\n",
    "| trees | maple, oak, palm, pine, willow |\n",
    "| vehicles 1 | bicycle, bus, motorcycle, pickup truck, train |\n",
    "| vehicles 2 | lawn-mower, rocket, streetcar, tank, tractor |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
